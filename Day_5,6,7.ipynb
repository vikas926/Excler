{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqq7nZs4Gn6s",
        "outputId": "2cc7b458-4eca-4b54-eb2f-59a0bb3fcaea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text: hello world i am here to explore\n",
            "hello: 1\n",
            "world: 1\n",
            "i: 1\n",
            "am: 1\n",
            "here: 1\n",
            "to: 1\n",
            "explore: 1\n"
          ]
        }
      ],
      "source": [
        "#1. Write a Python program to calculate the frequency of each word in a given text. Print the\n",
        "words and their corresponding counts\n",
        "from collections import Counter\n",
        "\n",
        "def word_frequency(text):\n",
        "    # Normalize the text: remove punctuation and convert to lowercase\n",
        "    text = text.lower()\n",
        "    words = text.split()\n",
        "\n",
        "    # Count word frequencies\n",
        "    word_count = Counter(words)\n",
        "\n",
        "    # Display each word and its count\n",
        "    for word, count in word_count.items():\n",
        "        print(f\"{word}: {count}\")\n",
        "\n",
        "# Example input\n",
        "text_input = input(\"Enter text: \")\n",
        "word_frequency(text_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Python program to using NLTK and Spacy\n",
        "#Convert text to lowercase.\n",
        "#Remove stopwords using NLTK\n",
        "text = \"Hello World\"\n",
        "lowercase_text = text.lower()\n",
        "print(\"Lowercase Text:\", lowercase_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2azkT1iHE44",
        "outputId": "f5cbb08b-d6f2-42fb-c78d-e518f17f5a05"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercase Text: hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove stopwords using NLTK\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "text = \"NLP is a Natural language process which is very useful for sentiment analysis and it has many real time projects though itd very easy to do and it is a beautiful language and it is specificially and widely used in business purposes\"\n",
        "words = text.split()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "filtered_text = ''.join(filtered_words)\n",
        "print(\"Filtered Text:\",filtered_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pauJXpxhHlHv",
        "outputId": "3d78339d-546b-41ee-9800-66f2b3d8f169"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Text: NLPNaturallanguageprocessusefulsentimentanalysismanyrealtimeprojectsthoughitdeasybeautifullanguagespecificiallywidelyusedbusinesspurposes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write a Python script that:\n",
        "#1. Use Genism to preprocess data from a sample text file, follow basic procedures like tokenization, stemming, lemmatization etc.\n",
        "import nltk\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "# Download necessary resources for NLTK\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Function for text preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Tokenization using Gensim's simple_preprocess\n",
        "    tokens = simple_preprocess(text, deacc=True)  # deacc removes punctuations\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in STOPWORDS]\n",
        "\n",
        "    # Stemming using NLTK\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    # Lemmatization using NLTK\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in stemmed_tokens]\n",
        "\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Example input sentence\n",
        "text_data = \"The quick brown fox jumps over the lazy dog. This is a test document for text preprocessing.\"\n",
        "\n",
        "# Preprocess the text\n",
        "preprocessed_data = preprocess_text(text_data)\n",
        "\n",
        "# Display the results\n",
        "print(\"Preprocessed Text Tokens:\")\n",
        "print(preprocessed_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O4e4mU6J53d",
        "outputId": "9b96e185-3e42-4be3-a744-6247ba387d70"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Text Tokens:\n",
            "['quick', 'brown', 'fox', 'jump', 'lazi', 'dog', 'test', 'document', 'text', 'preprocess']\n"
          ]
        }
      ]
    }
  ]
}